{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import guidance\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"endpoint\")\n",
    "client_id = os.getenv(\"client_id\")\n",
    "scopes = os.getenv(\"scopes\")\n",
    "authority = os.getenv(\"authority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, List\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = guidance.llms.MSALOpenAI(\n",
    "#     \"dev-chat-completion-gpt-35-turbo\", #\"text-davinci-003\",\n",
    "#     endpoint=endpoint, \n",
    "#     client_id=client_id,\n",
    "#     scopes=[scopes],\n",
    "#     authority=authority\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "from typing import Set, Dict, Tuple\n",
    "\n",
    "api_key = \"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\"\n",
    "org = \"org-vzLKqr2IxHajiWH6yz2Qzg64\"\n",
    "\n",
    "gpt4 = guidance.llms.OpenAI(api_key=api_key, model=\"gpt-4\") #, organization=org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from suggesters import ModelSuggester, ModelType, RelationshipStrategy\n",
    "m = ModelSuggester()\n",
    "model_type = ModelType.Chat\n",
    "relationship_strategy = RelationshipStrategy.Parent\n",
    "\n",
    "m.suggest_relationships()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from suggesters import ModelSuggester\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ms = ModelSuggester()\n",
    "\n",
    "edges = ms.suggest_relationships(\n",
    "    treatment=treatment, \n",
    "    outcome=outcome,    \n",
    "    factors_list=variables_list, \n",
    "    llm=gpt4)\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add(edges)\n",
    "nx.draw(\n",
    "    G, \n",
    "    with_labels=True, \n",
    "    font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Method: Add to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def add_to_csv(file_path, row):\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Method: Ask LLM and Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai_and_save_to_csv(factors_list: List[str], edges: List[Tuple[str, str]], analysis_context, experts, treatment, outcome, llm: guidance.llms, file_name:str, model_type, relationship_strategy, temperatures=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "\n",
    "    for temperature in temperatures:\n",
    "        sug_edges, edge_counter = m.suggest_relationships(\n",
    "            analysis_context=analysis_context, \n",
    "            factors_list=factors_list, \n",
    "            experts=experts, \n",
    "            treatment=treatment, \n",
    "            outcome=outcome, \n",
    "            model_type=model_type,\n",
    "            relationship_strategy=relationship_strategy, \n",
    "            llm=llm, \n",
    "            temperature=temperature\n",
    "        )     \n",
    "\n",
    "        information : Dict[Tuple[str, str], Dict[str, str]] = dict()\n",
    "        edge_info: Dict[str, str]\n",
    "\n",
    "        for var_a in factors_list:\n",
    "            for var_b in factors_list:\n",
    "                if var_a != var_b:\n",
    "                    accuracy = \"\"\n",
    "                    correct = \"\"\n",
    "                    llm_sug = \"\"\n",
    "                    truth = \"\"\n",
    "                    # true positive\n",
    "                    if (var_a, var_b) in sug_edges and (var_a, var_b) in edges:\n",
    "                        accuracy = \"TP\"\n",
    "                        correct = \"1\"\n",
    "                        llm_sug = \"1\"\n",
    "                        truth = \"1\"\n",
    "                    # false positive\n",
    "                    elif (var_a, var_b) in sug_edges and (var_a, var_b) not in edges:\n",
    "                        accuracy = \"FP\"\n",
    "                        correct = \"0\"\n",
    "                        llm_sug = \"1\"\n",
    "                        truth = \"0\"\n",
    "                    # false negative\n",
    "                    elif (var_a, var_b) not in sug_edges and (var_a, var_b) in edges:\n",
    "                        accuracy = \"FN\"\n",
    "                        correct = \"0\"  \n",
    "                        llm_sug = \"0\"    \n",
    "                        truth = \"1\"        \n",
    "                    # true negative\n",
    "                    elif (var_a, var_b) not in sug_edges and (var_a, var_b) not in edges:\n",
    "                        accuracy = \"TN\"\n",
    "                        correct = \"1\"\n",
    "                        llm_sug = \"0\"\n",
    "                        truth = \"0\"\n",
    "\n",
    "                    new_row = [temperature, var_a, var_b, correct, llm_sug, truth, accuracy]\n",
    "                    add_to_csv(file_name, new_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuebingen Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from a csv file helper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from a text file helper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_context_to_dictionary(pairs_dict: Dict[str, Dict[str, str]]):    \n",
    "    for pair_number in pairs_dict:\n",
    "        file_name = 'notebooks/tuebingen_causality_pairs/pairs/' + pair_number + '_des.txt'\n",
    "        try:\n",
    "            with open(file_name, 'r') as file:\n",
    "                metadata = file.read()\n",
    "                pairs_dict[pair_number][\"context\"] = metadata \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File '{file_name}' not found. Skipping...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing file '{file_name}': {str(e)}\")\n",
    "    \n",
    "    return pairs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './notebooks/tuebingen_causality_pairs/tuebingen_pairs.csv'\n",
    "rows = read_csv_file(file_path)\n",
    "\n",
    "pairs_dict : Dict[str, Dict[str, str]] = {}  \n",
    "\n",
    "# Print the pairs list\n",
    "for values in rows: \n",
    "    pairs_dict[values[0]] = {\"var1\": values[1], \"var2\": values[2], \"ground_truth\": values[3]}\n",
    "\n",
    "for pair in pairs_dict:\n",
    "    print(pair)\n",
    "    if pairs_dict[pair][\"ground_truth\"] == \" R\":\n",
    "        print(pairs_dict[pair][\"ground_truth\"])\n",
    "        pairs_dict[pair][\"truth_ab\"] = 1\n",
    "        pairs_dict[pair][\"truth_ba\"] = 0\n",
    "    elif pairs_dict[pair][\"ground_truth\"] == \" L\":\n",
    "        print(pairs_dict[pair][\"ground_truth\"])\n",
    "        pairs_dict[pair][\"truth_ab\"] = 0\n",
    "        pairs_dict[pair][\"truth_ba\"] = 1 \n",
    "\n",
    "read_context_to_dictionary(pairs_dict)\n",
    "\n",
    "for key, value in pairs_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"tuebingen_davinci3.csv\"\n",
    "new_row = [\"temperature\", \"use_domain\", \"use_context\", \"pair_id\", \"var1\", \"var2\", \"llm_ab\", \"llm_ba\", 'correct_ab_sug', 'correct_ba_sug']\n",
    "add_to_csv(csv_file_path, new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sea Ice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_ice_variables = [\n",
    "    \"geopotential_heights\", \n",
    "    \"relative_humidity\", \n",
    "    \"sea_level_pressure\",  \n",
    "    \"zonal_wind_at_10_meters\", \n",
    "    \"meridional_wind_at_10_meters\", \n",
    "    \"sensible_plus_latent_heat_flux\", \n",
    "    \"total_precipitation\", \n",
    "    \"total_cloud_cover\", \n",
    "    \"total_cloud_water_path\",  \n",
    "    \"surface_net_shortwave_flux\", \n",
    "    \"surface_net_longwave_flux\", \n",
    "    \"northern_hemisphere_sea_ice_extent\",\n",
    "]\n",
    "\n",
    "treatment = \"surface_net_longwave_flux\"\n",
    "outcome = \"northern_hemisphere_sea_ice_extent\"\n",
    "\n",
    "# ground truth confounders to the relationship between surface_net_longwave_flux and northern_hemisphere_sea_ice_extent\n",
    "sea_ice_confounders = [\"total_precipitation\"]\n",
    "   \n",
    "sea_ice_relationships: List[Tuple[str, str]] = [\n",
    "    (\"surface_net_longwave_flux\", \"northern_hemisphere_sea_ice_extent\"), \n",
    "    \n",
    "    (\"geopotential_heights\", \"surface_net_longwave_flux\"), \n",
    "    (\"geopotential_heights\", \"relative_humidity\"), \n",
    "    (\"geopotential_heights\", \"sea_level_pressure\"), \n",
    "\n",
    "    (\"relative_humidity\", \"total_cloud_cover\"), \n",
    "    (\"relative_humidity\", \"total_cloud_water_path\"),\n",
    "    (\"relative_humidity\", \"total_precipitation\"), \n",
    "    (\"relative_humidity\", \"surface_net_longwave_flux\"),\n",
    "\n",
    "    (\"sea_level_pressure\", \"relative_humidity\"), \n",
    "    (\"sea_level_pressure\", \"geopotential_heights\"), \n",
    "    (\"sea_level_pressure\", \"zonal_wind_at_10_meters\"), \n",
    "    (\"sea_level_pressure\", \"northern_hemisphere_sea_ice_extent\"), \n",
    "    (\"sea_level_pressure\", \"sensible_plus_latent_heat_flux\"), \n",
    "    (\"sea_level_pressure\", \"meridional_wind_at_10_meters\"),\n",
    "\n",
    "    (\"zonal_wind_at_10_meters\", \"northern_hemisphere_sea_ice_extent\"),\n",
    "    (\"zonal_wind_at_10_meters\", \"sensible_plus_latent_heat_flux\"), \n",
    "    \n",
    "    (\"meridional_wind_at_10_meters\", \"northern_hemisphere_sea_ice_extent\"),\n",
    "    (\"meridional_wind_at_10_meters\", \"sensible_plus_latent_heat_flux\"), \n",
    "   \n",
    "    (\"sensible_plus_latent_heat_flux\", \"northern_hemisphere_sea_ice_extent\"), \n",
    "    (\"sensible_plus_latent_heat_flux\", \"sea_level_pressure\"), \n",
    "    (\"sensible_plus_latent_heat_flux\", \"zonal_wind_at_10_meters\"), \n",
    "    (\"sensible_plus_latent_heat_flux\", \"meridional_wind_at_10_meters\"), \n",
    "    (\"sensible_plus_latent_heat_flux\", \"total_precipitation\"), \n",
    "    (\"sensible_plus_latent_heat_flux\", \"total_cloud_cover\"), \n",
    "    (\"sensible_plus_latent_heat_flux\", \"total_cloud_water_path\"), \n",
    "    \n",
    "    (\"total_precipitation\", \"northern_hemisphere_sea_ice_extent\"),\n",
    "    (\"total_precipitation\", \"relative_humidity\"),\n",
    "    (\"total_precipitation\", \"sensible_plus_latent_heat_flux\"),\n",
    "    (\"total_precipitation\", \"surface_net_longwave_flux\"),\n",
    "    (\"total_precipitation\", \"total_cloud_cover\"),\n",
    "    (\"total_precipitation\", \"total_cloud_water_path\"),\n",
    "   \n",
    "    (\"total_cloud_water_path\", \"total_precipitation\"), \n",
    "    (\"total_cloud_water_path\", \"sensible_plus_latent_heat_flux\"), \n",
    "    (\"total_cloud_water_path\", \"relative_humidity\"), \n",
    "    (\"total_cloud_water_path\", \"surface_net_longwave_flux\"), \n",
    "    (\"total_cloud_water_path\", \"surface_net_shortwave_flux\"), \n",
    "    \n",
    "    (\"total_cloud_cover\", \"total_precipitation\"),\n",
    "    (\"total_cloud_cover\", \"sensible_plus_latent_heat_flux\"),\n",
    "    (\"total_cloud_cover\", \"relative_humidity\"),\n",
    "    (\"total_cloud_cover\", \"surface_net_longwave_flux\"),\n",
    "    (\"total_cloud_cover\", \"surface_net_shortwave_flux\"), \n",
    "    \n",
    "    (\"surface_net_shortwave_flux\", \"northern_hemisphere_sea_ice_extent\"),\n",
    "    \n",
    "    (\"northern_hemisphere_sea_ice_extent\", \"sea_level_pressure\"),\n",
    "    (\"northern_hemisphere_sea_ice_extent\", \"zonal_wind_at_10_meters\"),\n",
    "    (\"northern_hemisphere_sea_ice_extent\", \"meridional_wind_at_10_meters\"),\n",
    "    (\"northern_hemisphere_sea_ice_extent\", \"sensible_plus_latent_heat_flux\"),\n",
    "    (\"northern_hemisphere_sea_ice_extent\", \"surface_net_shortwave_flux\"),\n",
    "    (\"northern_hemisphere_sea_ice_extent\", \"surface_net_longwave_flux\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_ice_domain_experts_ycontext_file_path = \"sea_ice_gpt4_askparents_domain_experts_ycontext.csv\"\n",
    "sea_ice_causality_experts_ycontext_file_path = \"sea_ice_gpt4_askparents_causality_experts_ycontext.csv\"\n",
    "sea_ice_domain_experts_ncontext_file_path = \"sea_ice_gpt4_askparents_domain_experts_ncontext.csv\"\n",
    "sea_ice_causality_experts_ncontext_file_path = \"sea_ice_gpt4_askparents_causality_experts_ncontext.csv\"\n",
    "\n",
    "model_type = ModelType.Chat\n",
    "\n",
    "analysis_context = \"about the atmospheric, climate, and physical factors that influence and cause changes to the northern sea ice extent\"\n",
    "no_context = \"causal mechanisms\"\n",
    "\n",
    "causal_experts = [\"answering questions about causality, you are a helpful causality assistant \", \"causality, you are an intelligent AI with expertise in causality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expertises = m.suggest_domain_expertises(analysis_context=analysis_context, factors=sea_ice_variables, n_experts=5,  model_type=ModelType.Chat, llm=gpt4)\n",
    "\n",
    "expertises = [\"cliamte scientist\", \"atmospheric scientist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggest Parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Using domain experts and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = [\"temperature\", \"var1\", \"var2\", \"correct_sug\", \"llm_sug\", \"truth\", \"accuracy\"]\n",
    "add_to_csv(sea_ice_domain_experts_ycontext_file_path, new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_openai_and_save_to_csv(factors_list=sea_ice_variables, edges=sea_ice_relationships, analysis_context=analysis_context, experts=expertises, treatment=treatment, outcome=outcome, llm=gpt4, file_name=sea_ice_domain_experts_ycontext_file_path, model_type=ModelType.Chat, relationship_strategy=RelationshipStrategy.Parent, temperatures=[0.3, 0.5, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Using causal experts and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = [\"temperature\", \"var1\", \"var2\", \"correct_sug\", \"llm_sug\", \"truth\", \"accuracy\"]\n",
    "add_to_csv(sea_ice_causality_experts_ycontext_file_path, new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_openai_and_save_to_csv(factors_list=sea_ice_variables, edges=sea_ice_relationships, analysis_context=analysis_context, experts=causal_experts, treatment=treatment, outcome=outcome, llm=gpt4, file_name=sea_ice_causality_experts_ycontext_file_path, model_type=ModelType.Chat, relationship_strategy=RelationshipStrategy.Parent, temperatures=[0.3, 0.5, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Using domain experts without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = [\"temperature\", \"var1\", \"var2\", \"correct_sug\", \"llm_sug\", \"truth\", \"accuracy\"]\n",
    "add_to_csv(sea_ice_domain_experts_ncontext_file_path, new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_openai_and_save_to_csv(factors_list=sea_ice_variables, edges=sea_ice_relationships, analysis_context=no_context, experts=expertises, treatment=treatment, outcome=outcome, llm=gpt4, file_name=sea_ice_domain_experts_ncontext_file_path, model_type=ModelType.Chat, relationship_strategy=RelationshipStrategy.Parent, temperatures=[0.7])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Using causal experts without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = [\"temperature\", \"var1\", \"var2\", \"correct_sug\", \"llm_sug\", \"truth\", \"accuracy\"]\n",
    "add_to_csv(sea_ice_causality_experts_ncontext_file_path, new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_openai_and_save_to_csv(factors_list=sea_ice_variables, edges=sea_ice_relationships, analysis_context=no_context, experts=causal_experts, treatment=treatment, outcome=outcome, llm=gpt4, file_name=sea_ice_causality_experts_ncontext_file_path, model_type=ModelType.Chat, relationship_strategy=RelationshipStrategy.Parent, temperatures=[0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggest Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_ice_pairwise_domain_experts_ycontext_file_path = \"sea_ice_gpt4_pairwise_domain_experts_ycontext.csv\"\n",
    "sea_ice_pairwise_causality_experts_ycontext_file_path = \"sea_ice_gpt4_pairwise_causality_experts_ycontext.csv\"\n",
    "sea_ice_pairwise_domain_experts_ncontext_file_path = \"sea_ice_gpt4_pairwise_domain_experts_ncontext.csv\"\n",
    "sea_ice_pairwise_causality_experts_ncontext_file_path = \"sea_ice_gpt4_pairwise_causality_experts_ncontext.csv\"\n",
    "\n",
    "model_type = ModelType.Chat\n",
    "relationship_strategy = RelationshipStrategy.Pairwise\n",
    "\n",
    "analysis_context = \"about the atmospheric, climate, and physical factors that influence and cause changes to the northern sea ice extent\"\n",
    "no_context = \"causal mechanisms\"\n",
    "\n",
    "causal_experts = [\"answering questions about causality, you are a helpful causality assistant \", \"causality, you are an intelligent AI with expertise in causality\"]\n",
    "\n",
    "expertises = [\"climate scientist\", \"atmospheric scientist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = [\"temperature\", \"var1\", \"var2\", \"correct_sug\", \"llm_sug\", \"truth\", \"accuracy\"]\n",
    "add_to_csv(sea_ice_pairwise_domain_experts_ycontext_file_path, new_row)\n",
    "add_to_csv(sea_ice_pairwise_causality_experts_ycontext_file_path, new_row)\n",
    "add_to_csv(sea_ice_pairwise_domain_experts_ncontext_file_path, new_row)\n",
    "add_to_csv(sea_ice_pairwise_causality_experts_ncontext_file_path, new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=expertises,                # yes expert\n",
    "    analysis_context=analysis_context, # yes context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_domain_experts_ycontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.3])\n",
    "\n",
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=expertises,                # yes expert\n",
    "    analysis_context=analysis_context, # yes context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_domain_experts_ycontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.5])\n",
    "\n",
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=expertises,                # yes expert\n",
    "    analysis_context=analysis_context, # yes context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_domain_experts_ycontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=expertises,                # yes expert\n",
    "    analysis_context=no_context,       # no context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_domain_experts_ncontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.3])\n",
    "\n",
    "# ask_openai_and_save_to_csv(\n",
    "#     factors_list=sea_ice_variables, \n",
    "#     edges=sea_ice_relationships, \n",
    "#     experts=expertises,                # yes expert\n",
    "#     analysis_context=no_context,       # no context\n",
    "#     treatment=treatment, \n",
    "#     outcome=outcome, \n",
    "#     llm=gpt4, \n",
    "#     file_name=sea_ice_pairwise_domain_experts_ncontext_file_path, \n",
    "#     model_type=ModelType.Chat, \n",
    "#     relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "#     temperatures=[0.5])\n",
    "\n",
    "# ask_openai_and_save_to_csv(\n",
    "#     factors_list=sea_ice_variables, \n",
    "#     edges=sea_ice_relationships, \n",
    "#     experts=expertises,                # yes expert\n",
    "#     analysis_context=no_context,       # no context\n",
    "#     treatment=treatment, \n",
    "#     outcome=outcome, \n",
    "#     llm=gpt4, \n",
    "#     file_name=sea_ice_pairwise_domain_experts_ncontext_file_path, \n",
    "#     model_type=ModelType.Chat, \n",
    "#     relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "#     temperatures=[0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=causal_experts,                # no expert\n",
    "    analysis_context=analysis_context,     # yes context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_causality_experts_ycontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.3])\n",
    "\n",
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=causal_experts,                # no expert\n",
    "    analysis_context=analysis_context,     # yes context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_causality_experts_ycontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.5])\n",
    "\n",
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=causal_experts,                # no expert\n",
    "    analysis_context=analysis_context,     # yes context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_causality_experts_ycontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=causal_experts,                # no expert\n",
    "    analysis_context=no_context,           # no context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_causality_experts_ncontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.3])\n",
    "\n",
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=causal_experts,                # no expert\n",
    "    analysis_context=no_context,           # no context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_causality_experts_ncontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.5])\n",
    "\n",
    "ask_openai_and_save_to_csv(\n",
    "    factors_list=sea_ice_variables, \n",
    "    edges=sea_ice_relationships, \n",
    "    experts=causal_experts,                # no expert\n",
    "    analysis_context=no_context,           # no context\n",
    "    treatment=treatment, \n",
    "    outcome=outcome, \n",
    "    llm=gpt4, \n",
    "    file_name=sea_ice_pairwise_causality_experts_ncontext_file_path, \n",
    "    model_type=ModelType.Chat, \n",
    "    relationship_strategy=RelationshipStrategy.Pairwise, \n",
    "    temperatures=[0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "sea_ice_parents_domain_experts_ycontext_file_path = \"sea_ice_gpt4_askparents_domain_experts_ycontext.csv\"\n",
    "sea_ice_parents_causality_experts_ycontext_file_path = \"sea_ice_gpt4_askparents_causality_experts_ycontext.csv\"\n",
    "sea_ice_parents_domain_experts_ncontext_file_path = \"sea_ice_gpt4_askparents_domain_experts_ncontext.csv\"\n",
    "sea_ice_parents_causality_experts_ncontext_file_path = \"sea_ice_gpt4_askparents_causality_experts_ncontext.csv\"\n",
    "\n",
    "\n",
    "csv_file_path = sea_ice_parents_domain_experts_ycontext_file_path\n",
    "domain_yes_context = {}\n",
    "domain_no_context = {}\n",
    "causal_yes_context = {}\n",
    "causal_no_context = {}\n",
    "\n",
    "def csv_to_dictionary(file_path):\n",
    "    data_dict = {}\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        header = next(csv_reader)  # Read and skip the header row\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            key = tuple(row[:3])  # Create a tuple from the first three values\n",
    "            value_dict = {header[i]: row[i] for i in range(3, len(header))}  # Create a dictionary of column headers and values\n",
    "            data_dict[key] = value_dict  # Add the value dictionary to the main dictionary\n",
    "    # print(data_dict)\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def count_each_accuracy(data_dict):\n",
    "\n",
    "    count_dict = {}\n",
    "    for i in [0.3, 0.5, 0.7]:\n",
    "        count_dict[f\"{i} TP\"] = 0\n",
    "        count_dict[f\"{i} TN\"] = 0\n",
    "        count_dict[f\"{i} FP\"] = 0\n",
    "        count_dict[f\"{i} FN\"] = 0\n",
    "    # print(count_dict)\n",
    "\n",
    "    \n",
    "    for key, value in data_dict.items():\n",
    "\n",
    "        # print(value)\n",
    "        if value[\"llm_sug\"] == \"1\" and value[\"truth\"] == \"1\":\n",
    "            vals = count_dict[f\"{key[0]} TP\"]\n",
    "            count_dict[f\"{key[0]} TP\"] = vals+1\n",
    "        elif value[\"llm_sug\"] == \"0\" and value[\"truth\"] == \"0\":\n",
    "            vals = count_dict[f\"{key[0]} TN\"]\n",
    "            count_dict[f\"{key[0]} TN\"] = vals+1\n",
    "        elif value[\"llm_sug\"] == \"1\" and value[\"truth\"] == \"0\":\n",
    "            vals = count_dict[f\"{key[0]} FP\"]\n",
    "            count_dict[f\"{key[0]} FP\"] = vals+1\n",
    "        elif value[\"llm_sug\"] == \"0\" and value[\"truth\"] == \"1\":\n",
    "            vals = count_dict[f\"{key[0]} FN\"]\n",
    "            count_dict[f\"{key[0]} FN\"] = vals+1\n",
    "    \n",
    "    return count_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_no_context_count = count_each_accuracy(csv_to_dictionary(\"sea_ice_gpt4_askparents_domain_experts_ycontext.csv\"))\n",
    "print(domain_no_context_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_no_context_count = count_each_accuracy(csv_to_dictionary(\"sea_ice_gpt4_askparents_domain_experts_ncontext.csv\"))\n",
    "print(domain_no_context_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_yes_context_count = count_each_accuracy(csv_to_dictionary(\"sea_ice_gpt4_askparents_causality_experts_ycontext.csv\"))\n",
    "print(causal_yes_context_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_no_context_count = count_each_accuracy(csv_to_dictionary(\"sea_ice_gpt4_askparents_causality_experts_ncontext.csv\"))\n",
    "print(causal_no_context_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
